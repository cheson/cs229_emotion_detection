{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Cloud Vision - Face Detection API ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# Copyright 2015 Google, Inc\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\"\"\"Draws squares around faces in the given image.\"\"\"\n",
    "import argparse\n",
    "import base64\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "\n",
    "from googleapiclient import discovery\n",
    "import httplib2\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import os\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = './auth.json'\n",
    "\n",
    "\n",
    "# [START get_vision_service]\n",
    "DISCOVERY_URL='https://vision.googleapis.com/$discovery/rest?version=v1'\n",
    "\n",
    "\n",
    "def get_vision_service():\n",
    "    credentials = GoogleCredentials.get_application_default()\n",
    "    return discovery.build('vision', 'v1', credentials=credentials,\n",
    "                           discoveryServiceUrl=DISCOVERY_URL)\n",
    "# [END get_vision_service]\n",
    "\n",
    "\n",
    "# [START detect_face]\n",
    "def detect_face(face_file, max_results=4):\n",
    "    \"\"\"Uses the Vision API to detect faces in the given file.\n",
    "    Args:\n",
    "        face_file: A file-like object containing an image with faces.\n",
    "    Returns:\n",
    "        An array of dicts with information about the faces in the picture.\n",
    "    \"\"\"\n",
    "    image_content = face_file.read()\n",
    "    batch_request = [{\n",
    "        'image': {\n",
    "            'content': base64.b64encode(image_content).decode('UTF-8')\n",
    "            },\n",
    "        'features': [{\n",
    "            'type': 'FACE_DETECTION',\n",
    "            'maxResults': max_results,\n",
    "            }]\n",
    "        }]\n",
    "\n",
    "    service = get_vision_service()\n",
    "    request = service.images().annotate(body={\n",
    "        'requests': batch_request,\n",
    "        })\n",
    "    response = request.execute()\n",
    "    return response['responses'][0]['faceAnnotations']\n",
    "# [END detect_face]\n",
    "\n",
    "# [START print_landmarks]\n",
    "def print_landmarks(face, image):\n",
    "    \"\"\"prints out landmark results for a face object\"\"\"\n",
    "    coordinates = list()\n",
    "    width = image.size[0]\n",
    "    height = image.size[1]\n",
    "    x_norm = y_norm = float(250); #relatively arbitrary, right now just approximated by cropped face size from ck dataset\n",
    "    x_norm_ratio = x_norm/width;\n",
    "    y_norm_ratio = y_norm/height;\n",
    "    for landmark in face['landmarks']:\n",
    "        # print landmark['type']\n",
    "        # print 'x: ' + str(landmark['position']['x'])\n",
    "        # print 'y: ' + str(landmark['position']['y'])\n",
    "        # print 'z: ' + str(landmark['position']['z'])\n",
    "        coordinates.append((landmark['position']['x'])*x_norm_ratio)\n",
    "        coordinates.append((landmark['position']['y'])*y_norm_ratio)\n",
    "        coordinates.append(landmark['position']['z'])\n",
    "    return coordinates\n",
    "\n",
    "    #print face['landmarks'][1]\n",
    "# [END print_landmarks]\n",
    "\n",
    "# def normalize_landmark(width, height, x_coord, y_coord, x_norm, y_norm): #norm - 250, 250\n",
    "#     #return ()\n",
    "#     return 0\n",
    "\n",
    "# [START crop_face]\n",
    "def crop_face(image, face, output_filename):\n",
    "    \"\"\"Crops a polygon around the faces, then saves to output_filename.\n",
    "    Args:\n",
    "      image: a file containing the image with the faces.\n",
    "      faces: a list of faces found in the file. This should be in the format\n",
    "          returned by the Vision API.\n",
    "      output_filename: the name of the image file to be created, where the faces\n",
    "          have polygons drawn around them.\n",
    "    \"\"\"\n",
    "    im = Image.open(image)\n",
    "\n",
    "    box = [(v.get('x', 0.0), v.get('y', 0.0)) for v in face['fdBoundingPoly']['vertices']]\n",
    "    corners = box[0] + box[2]\n",
    "    im = im.crop(corners)\n",
    "    im.save('images/' + output_filename)\n",
    "    return im\n",
    "# [END crop_face]\n",
    "\n",
    "# [START face_detection]\n",
    "def face_detection(input_filename, output_filename, max_results):\n",
    "    with open(input_filename, 'rb') as image:\n",
    "        face = detect_face(image, 1)[0] #detects face in original image <- inefficient way to find crop region?\n",
    "        face_crop = crop_face(image, face, output_filename) #crop original image to just facial region\n",
    "        with open('images/' + output_filename, 'rb') as image_crop: #rerun facial detection on cropped face\n",
    "            face = detect_face(image_crop, 1)[0]\n",
    "        return print_landmarks(face, Image.open('images/'+output_filename))\n",
    "        #print('Writing to file %s' % output_filename)\n",
    "        # Reset the file pointer, so we can read the file again\n",
    "        #image.seek(0)\n",
    "        #highlight_faces(image, faces, output_filename)\n",
    "# [END face_detection]\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     parser = argparse.ArgumentParser(\n",
    "#         description='Detects faces in the given image.')\n",
    "#     parser.add_argument(\n",
    "#         'input_image', help='the image you\\'d like to detect faces in.')\n",
    "#     parser.add_argument(\n",
    "#         '--out', dest='output', default='out.jpg',\n",
    "#         help='the name of the output file.')\n",
    "#     parser.add_argument(\n",
    "#         '--max-results', dest='max_results', default=4,\n",
    "#         help='the max results of face detection.')\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "#     main(args.input_image, args.output, args.max_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[75.81367015209126,\n",
       " 83.23715874524714,\n",
       " -0.00054242183,\n",
       " 180.04882129277567,\n",
       " 78.53305703422053,\n",
       " 14.456583,\n",
       " 35.73074619771864,\n",
       " 59.44246958174905,\n",
       " 9.4364767,\n",
       " 103.66621673003803,\n",
       " 53.22846863117871,\n",
       " -14.290893,\n",
       " 156.07673954372626,\n",
       " 51.174287072243345,\n",
       " -7.1145382,\n",
       " 216.32480988593156,\n",
       " 53.97913403041825,\n",
       " 33.93354,\n",
       " 131.37735741444868,\n",
       " 74.72743916349809,\n",
       " -15.821347,\n",
       " 137.98660646387833,\n",
       " 131.50543726235742,\n",
       " -58.335003,\n",
       " 138.3024049429658,\n",
       " 174.43837452471485,\n",
       " -38.048069,\n",
       " 138.9680133079848,\n",
       " 212.615427756654,\n",
       " -35.473053,\n",
       " 93.38339733840304,\n",
       " 198.56468631178709,\n",
       " -16.282583,\n",
       " 177.31248098859314,\n",
       " 194.01611216730038,\n",
       " -4.5451975,\n",
       " 137.39018060836503,\n",
       " 191.52877376425855,\n",
       " -32.174747,\n",
       " 166.0429657794677,\n",
       " 144.23876425855514,\n",
       " -11.593722,\n",
       " 105.35092205323194,\n",
       " 147.40304182509507,\n",
       " -20.421896,\n",
       " 137.48161596958175,\n",
       " 151.84475285171104,\n",
       " -35.026592,\n",
       " 75.17877756653994,\n",
       " 74.9302633079848,\n",
       " -6.5142503,\n",
       " 98.85173954372624,\n",
       " 84.36564163498099,\n",
       " 3.1294875,\n",
       " 74.64830228136881,\n",
       " 92.17451520912547,\n",
       " -2.2361133,\n",
       " 51.6341397338403,\n",
       " 85.87262357414448,\n",
       " 7.3813896,\n",
       " 73.38066254752852,\n",
       " 83.20448003802282,\n",
       " -3.0883443,\n",
       " 183.23747148288973,\n",
       " 70.85881368821292,\n",
       " 8.2647047,\n",
       " 203.22027566539924,\n",
       " 80.33646577946769,\n",
       " 27.956003,\n",
       " 182.58260456273763,\n",
       " 87.5881036121673,\n",
       " 12.508552,\n",
       " 159.39790874524715,\n",
       " 82.21826425855512,\n",
       " 11.76806,\n",
       " 184.30664448669202,\n",
       " 79.03266634980989,\n",
       " 11.972785,\n",
       " 69.51603326996198,\n",
       " 42.79857414448669,\n",
       " -7.9380045,\n",
       " 186.78980038022814,\n",
       " 38.41764163498099,\n",
       " 8.0889187,\n",
       " -7.28216463878327,\n",
       " 158.99125475285172,\n",
       " 121.3275,\n",
       " 238.18430608365017,\n",
       " 149.76423003802282,\n",
       " 154.89421,\n",
       " 130.35639733840304,\n",
       " 50.34837262357414,\n",
       " -14.698672,\n",
       " 139.92679657794676,\n",
       " 263.83247148288973,\n",
       " -26.938465,\n",
       " 13.823230988593156,\n",
       " 220.839819391635,\n",
       " 66.43013,\n",
       " 235.66060836501902,\n",
       " 212.57673003802282,\n",
       " 96.740517]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test run\n",
    "face_detection('./images/CK+/cohn-kanade-plus-images/S051/002/S051_002_00000010.png', \"out.jpg\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "17\n",
      "18\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "40\n",
      "42\n",
      "43\n",
      "47\n",
      "48\n",
      "49\n",
      "51\n",
      "54\n",
      "55\n",
      "56\n",
      "58\n",
      "60\n",
      "61\n",
      "63\n",
      "66\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "77\n",
      "78\n",
      "80\n",
      "82\n",
      "84\n",
      "85\n",
      "86\n",
      "89\n",
      "90\n",
      "91\n",
      "93\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "110\n",
      "113\n",
      "114\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "138\n",
      "139\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "151\n",
      "153\n",
      "154\n",
      "155\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "162\n",
      "163\n",
      "164\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "173\n",
      "174\n",
      "175\n",
      "180\n",
      "181\n",
      "182\n",
      "187\n",
      "188\n",
      "189\n",
      "191\n",
      "192\n",
      "194\n",
      "197\n",
      "198\n",
      "200\n",
      "201\n",
      "205\n",
      "206\n",
      "207\n",
      "212\n",
      "214\n",
      "217\n",
      "220\n",
      "221\n",
      "222\n",
      "224\n",
      "225\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "236\n",
      "237\n",
      "241\n",
      "243\n",
      "246\n",
      "248\n",
      "249\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "259\n",
      "260\n",
      "262\n",
      "263\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "275\n",
      "276\n",
      "278\n",
      "279\n",
      "280\n",
      "283\n",
      "284\n",
      "286\n",
      "287\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "297\n",
      "298\n",
      "299\n",
      "302\n",
      "304\n",
      "307\n",
      "308\n",
      "309\n",
      "312\n",
      "313\n",
      "314\n",
      "317\n",
      "318\n",
      "320\n",
      "325\n",
      "326\n",
      "332\n",
      "349\n",
      "351\n",
      "353\n",
      "355\n",
      "357\n",
      "361\n",
      "366\n",
      "367\n",
      "369\n",
      "372\n",
      "374\n",
      "375\n",
      "376\n",
      "383\n",
      "388\n",
      "389\n",
      "394\n",
      "395\n",
      "397\n",
      "402\n",
      "403\n",
      "408\n",
      "409\n",
      "412\n",
      "416\n",
      "417\n",
      "422\n",
      "423\n",
      "424\n",
      "426\n",
      "429\n",
      "437\n",
      "439\n",
      "444\n",
      "452\n",
      "456\n",
      "458\n",
      "461\n",
      "462\n",
      "463\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "476\n",
      "477\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "484\n",
      "485\n",
      "486\n",
      "492\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "499\n",
      "502\n",
      "504\n",
      "506\n",
      "507\n",
      "509\n",
      "510\n",
      "512\n",
      "515\n",
      "517\n",
      "518\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "528\n",
      "529\n",
      "531\n",
      "533\n",
      "534\n",
      "535\n",
      "539\n",
      "540\n",
      "541\n",
      "544\n",
      "545\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from cd import cd\n",
    "\n",
    "def get_all_folders(folder_path):\n",
    "    with cd(folder_path):\n",
    "        all_folders = os.listdir('.')\n",
    "        directory_names = []\n",
    "        for directory in all_folders:\n",
    "            if directory[0] == '.':\n",
    "                continue\n",
    "            else:\n",
    "                directory_names.append(directory)\n",
    "        return directory_names\n",
    "    \n",
    "labels = list()\n",
    "features = list()\n",
    "\n",
    "def grab_data(Folder):\n",
    "    counter = 0\n",
    "    \n",
    "    ck_path = os.getcwd() + '/images/CK+/' + Folder + '/'\n",
    "    s_folders = get_all_folders(ck_path)\n",
    "    for folder in s_folders:\n",
    "        subdir_path = ck_path + folder + '/'\n",
    "        zero_folders = get_all_folders(subdir_path)\n",
    "        for zero in zero_folders:\n",
    "            img_level_path = subdir_path + zero + '/'\n",
    "            imgs = get_all_folders(img_level_path)\n",
    "            if Folder == 'Emotions': #LABELS\n",
    "                if len(imgs) > 0: #has an emotion label\n",
    "                    last_img_path = img_level_path + imgs[-1]\n",
    "                    f = open(last_img_path, 'r')\n",
    "                    emotion = f.read()\n",
    "                    labels.append(emotion[3]) #emotion[3] is the number denoting emotion\n",
    "                else: #has no emotion label\n",
    "                    labels.append(-1)\n",
    "            else: #FEATURES\n",
    "                last_img_path = img_level_path + imgs[-1]\n",
    "                if counter < len(labels): #TODO: CHECK THIS OFF BY ONE BULLSHIT\n",
    "                    if labels[counter] != -1:\n",
    "                        print counter\n",
    "                        features.append(face_detection(last_img_path, \"out.jpg\", 1))\n",
    "                counter += 1\n",
    "#                 if counter > 5: #because of bad internet\n",
    "#                     return\n",
    "\n",
    "grab_data('Emotions')\n",
    "grab_data('cohn-kanade-plus-images')\n",
    "temp_labels = list()\n",
    "for label in labels: #clean temp labels\n",
    "    if label != -1:\n",
    "        temp_labels.append(label)\n",
    "labels = temp_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  7.49039760e+01   8.30994489e+01   1.55015050e-03 ...,   2.30113339e+02\n",
      "    1.83858450e+02   1.13633720e+02]\n",
      " [  7.10013750e+01   8.52327887e+01  -1.73937260e-03 ...,   2.40550000e+02\n",
      "    2.07707702e+02   9.99086380e+01]\n",
      " [  6.97876577e+01   8.13421929e+01  -9.44529950e-04 ...,   2.36836720e+02\n",
      "    1.89456563e+02   9.12832720e+01]\n",
      " ..., \n",
      " [  6.05348421e+01   7.99952588e+01   2.10058920e-03 ...,   2.17467281e+02\n",
      "    1.93193500e+02   9.32072830e+01]\n",
      " [  7.25139441e+01   8.31724095e+01  -1.86232990e-03 ...,   2.30141464e+02\n",
      "    2.02685329e+02   8.96114810e+01]\n",
      " [  7.53539794e+01   8.68704841e+01   1.41212260e-03 ...,   2.37296381e+02\n",
      "    2.11071754e+02   6.83160550e+01]]\n"
     ]
    }
   ],
   "source": [
    "## CONVERT TO FLOATS ##\n",
    "import numpy as np\n",
    "\n",
    "labels = np.array(labels).astype(np.float) #does it matter if the labels are strings or floats? what's the difference?\n",
    "#print labels\n",
    "\n",
    "features = np.array(features).astype(np.float)\n",
    "print features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.,  7.,  1.,  5.,  7.,  6.,  4.,  1.,  3.,  5.,  7.,  6.,  1.,\n",
       "        5.,  7.,  1.,  3.,  7.,  6.,  1.,  5.,  1.,  1.,  7.,  1.,  4.,\n",
       "        3.,  5.,  7.,  1.,  5.,  7.,  3.,  5.,  7.,  1.,  5.,  7.,  6.,\n",
       "        1.,  5.,  7.,  5.,  3.,  3.,  1.,  6.,  7.,  4.,  3.,  4.,  7.,\n",
       "        1.,  5.,  7.,  3.,  7.,  5.,  3.,  7.,  5.,  4.,  7.,  3.,  7.,\n",
       "        3.,  1.,  5.,  4.,  3.,  7.,  5.,  7.,  3.,  5.,  7.,  1.,  3.,\n",
       "        7.,  4.,  5.,  7.,  3.,  7.,  5.,  3.,  4.,  7.,  5.,  3.,  7.,\n",
       "        5.,  7.,  5.,  6.,  4.,  7.,  5.,  3.,  7.,  5.,  6.,  1.,  7.,\n",
       "        1.,  5.,  3.,  5.,  7.,  4.,  3.,  7.,  3.,  5.,  7.,  5.,  3.,\n",
       "        7.,  6.,  1.,  5.,  3.,  1.,  5.,  7.,  3.,  4.,  7.,  3.,  5.,\n",
       "        7.,  3.,  5.,  1.,  7.,  3.,  5.,  7.,  3.,  7.,  5.,  3.,  7.,\n",
       "        3.,  5.,  7.,  6.,  3.,  7.,  6.,  3.,  7.,  1.,  3.,  5.,  7.,\n",
       "        4.,  5.,  7.,  3.,  7.,  5.,  7.,  3.,  5.,  1.,  7.,  3.,  7.,\n",
       "        5.,  1.,  7.,  3.,  1.,  4.,  5.,  7.,  1.,  5.,  6.,  5.,  7.,\n",
       "        5.,  7.,  3.,  5.,  6.,  7.,  3.,  5.,  7.,  3.,  5.,  3.,  5.,\n",
       "        7.,  5.,  3.,  7.,  1.,  5.,  7.,  7.,  4.,  3.,  3.,  6.,  3.,\n",
       "        5.,  7.,  3.,  6.,  3.,  5.,  1.,  3.,  5.,  7.,  7.,  1.,  3.,\n",
       "        1.,  7.,  6.,  1.,  7.,  5.,  7.,  6.,  5.,  7.,  3.,  5.,  7.,\n",
       "        4.,  1.,  7.,  4.,  1.,  7.,  7.,  4.,  3.,  5.,  6.,  5.,  4.,\n",
       "        7.,  3.,  7.,  1.,  7.,  5.,  1.,  3.,  5.,  7.,  1.,  3.,  5.,\n",
       "        7.,  1.,  6.,  3.,  5.,  7.,  6.,  5.,  3.,  6.,  4.,  3.,  5.,\n",
       "        7.,  1.,  7.,  5.,  1.,  5.,  3.,  7.,  5.,  7.,  6.,  1.,  5.,\n",
       "        7.,  6.,  5.,  4.,  7.,  5.,  6.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "        2.,  2.,  2.,  2.,  2.,  2.,  1.,  4.,  6.,  1.,  2.,  4.,  1.,\n",
       "        2.,  6.,  1.,  2.,  4.,  6.,  2.,  6.,  1.,  2.,  4.,  6.,  2.,\n",
       "        1.,  4.])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import os\n",
    "# if not os.path.exists('my_file'): numpy.savetxt('my_file', my_array)\n",
    "\n",
    "np.savetxt(\"ck_features_norm\", features)\n",
    "np.savetxt(\"ck_labels\", labels)\n",
    "np.loadtxt(\"ck_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7.49039760e+01,   8.30994489e+01,   1.55015050e-03, ...,\n",
       "          2.30113339e+02,   1.83858450e+02,   1.13633720e+02],\n",
       "       [  7.10013750e+01,   8.52327887e+01,  -1.73937260e-03, ...,\n",
       "          2.40550000e+02,   2.07707702e+02,   9.99086380e+01],\n",
       "       [  6.97876577e+01,   8.13421929e+01,  -9.44529950e-04, ...,\n",
       "          2.36836720e+02,   1.89456563e+02,   9.12832720e+01],\n",
       "       ..., \n",
       "       [  6.05348421e+01,   7.99952588e+01,   2.10058920e-03, ...,\n",
       "          2.17467281e+02,   1.93193500e+02,   9.32072830e+01],\n",
       "       [  7.25139441e+01,   8.31724095e+01,  -1.86232990e-03, ...,\n",
       "          2.30141464e+02,   2.02685329e+02,   8.96114810e+01],\n",
       "       [  7.53539794e+01,   8.68704841e+01,   1.41212260e-03, ...,\n",
       "          2.37296381e+02,   2.11071754e+02,   6.83160550e+01]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can now use np.loadtxt(\"\") to load in some of the google api generated landmark arrays.\n",
    "np.loadtxt(\"ck_features_norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327\n",
      "327\n"
     ]
    }
   ],
   "source": [
    "### ARRAY LENGTH SANITY CHECK ###\n",
    "print len(features)\n",
    "print len(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tools\n",
    "def train_test_split(split): \n",
    "    features_train = features[:split]\n",
    "    labels_train = labels[:split]\n",
    "    features_test = features[split:]\n",
    "    labels_test = labels[split:]\n",
    "    return (features_train, labels_train, features_test, labels_test)\n",
    "\n",
    "def num_of_label(val, labels):\n",
    "    count = 0\n",
    "    for label in labels:\n",
    "        if label == val:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def print_accuracy(labels_actual, labels_predicted):\n",
    "    correct = 0\n",
    "    wrong = 0\n",
    "    for index in range(len(labels_actual)):\n",
    "        if labels_actual[index] == labels_predicted[index]:\n",
    "            correct += 1\n",
    "        else:\n",
    "            wrong += 1\n",
    "    print 'num correct: ' + str(correct)\n",
    "    print 'num wrong: ' + str(wrong)\n",
    "    print 'accuracy: ' + str(float(correct)/(correct + wrong))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training SVM\n",
      "Finished Predictions for SVM\n",
      "training labels: \n",
      "[ 3.  7.  1.  5.  7.  6.  4.  1.  3.  5.  7.  6.  1.  5.  7.  1.  3.  7.\n",
      "  6.  1.  5.  1.  1.  7.  1.  4.  3.  5.  7.  1.  5.  7.  3.  5.  7.  1.\n",
      "  5.  7.  6.  1.  5.  7.  5.  3.  3.  1.  6.  7.  4.  3.  4.  7.  1.  5.\n",
      "  7.  3.  7.  5.  3.  7.  5.  4.  7.  3.  7.  3.  1.  5.  4.  3.  7.  5.\n",
      "  7.  3.  5.  7.  1.  3.  7.  4.  5.  7.  3.  7.  5.  3.  4.  7.  5.  3.\n",
      "  7.  5.  7.  5.  6.  4.  7.  5.  3.  7.  5.  6.  1.  7.  1.  5.  3.  5.\n",
      "  7.  4.  3.  7.  3.  5.  7.  5.  3.  7.  6.  1.  5.  3.  1.  5.  7.  3.\n",
      "  4.  7.  3.  5.  7.  3.  5.  1.  7.  3.  5.  7.  3.  7.  5.  3.  7.  3.\n",
      "  5.  7.  6.  3.  7.  6.  3.  7.  1.  3.  5.  7.  4.  5.  7.  3.  7.  5.\n",
      "  7.  3.  5.  1.  7.  3.  7.  5.  1.  7.  3.  1.  4.  5.  7.  1.  5.  6.\n",
      "  5.  7.  5.  7.  3.  5.  6.  7.  3.  5.  7.  3.  5.  3.  5.  7.  5.  3.\n",
      "  7.  1.  5.  7.  7.  4.  3.  3.  6.  3.  5.  7.  3.  6.  3.  5.  1.  3.\n",
      "  5.  7.  7.  1.  3.  1.  7.  6.  1.  7.  5.  7.  6.  5.  7.  3.  5.  7.\n",
      "  4.  1.  7.  4.  1.  7.  7.  4.  3.  5.  6.  5.  4.  7.  3.  7.  1.  7.\n",
      "  5.  1.  3.  5.  7.  1.  3.  5.  7.  1.  6.  3.  5.  7.  6.  5.  3.  6.]\n",
      "TRAIN: num of label 0: 0\n",
      "TRAIN: num of label 1: 36\n",
      "TRAIN: num of label 2: 0\n",
      "TRAIN: num of label 3: 57\n",
      "TRAIN: num of label 4: 18\n",
      "TRAIN: num of label 5: 62\n",
      "TRAIN: num of label 6: 20\n",
      "TRAIN: num of label 7: 77\n",
      "predictions: \n",
      "[ 3.  7.  5.  5.  6.  1.  7.  7.  7.  7.  5.  3.  5.  3.  5.  5.  7.  5.\n",
      "  7.  3.  1.  3.  3.  4.  7.  7.  7.  4.  4.  7.  7.  5.  5.  7.  5.  5.\n",
      "  5.  7.  5.  7.  7.  4.  6.  1.  5.  4.  6.  4.  4.  1.  5.  7.  5.  1.\n",
      "  5.  5.  4.]\n",
      "actual: \n",
      "[ 4.  3.  5.  7.  1.  7.  5.  1.  5.  3.  7.  5.  7.  6.  1.  5.  7.  6.\n",
      "  5.  4.  7.  5.  6.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  1.\n",
      "  4.  6.  1.  2.  4.  1.  2.  6.  1.  2.  4.  6.  2.  6.  1.  2.  4.  6.\n",
      "  2.  1.  4.]\n",
      "num correct: 4\n",
      "num wrong: 53\n",
      "accuracy: 0.0701754385965\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "#X is a matrix of input examples [[x1.....xn],...[x1,..., xn]]\n",
    "#Y is a vector of labels corresponding to emotion [1, 2, 8, ... yn]\n",
    "\n",
    "\n",
    "def train(X, y):\n",
    "#    clf = svm.SVC(decision_function_shape='ovo')\n",
    "    clf = svm.SVC(kernel='linear', C=1)\n",
    "#     clf = svm.LinearSVC()\n",
    "    clf.fit(X,y)\n",
    "    print 'Finished Training SVM'\n",
    "    return clf\n",
    "\n",
    "def test(clf, X):\n",
    "    #Takes all examples to predict and returns an array of lables\n",
    "    predictions = clf.predict(X)\n",
    "    print 'Finished Predictions for SVM'\n",
    "    return predictions\n",
    "\n",
    "############ Sample usage ####################\n",
    "\n",
    "#X = [[0,1], [3,4], [6,2], [1,2]]\n",
    "#y = [1,2,3,4]\n",
    "    \n",
    "splits = train_test_split(270)\n",
    "features_train = splits[0]\n",
    "labels_train = splits[1]\n",
    "features_test = splits[2]\n",
    "labels_test = splits[3]\n",
    "\n",
    "clf = train(features_train, labels_train)\n",
    "predictions = test(clf, features_test)\n",
    "\n",
    "# print(clf.score(features_test, labels_test))\n",
    "\n",
    "print \"training labels: \"\n",
    "print labels_train\n",
    "\n",
    "for val in range (0, 8):\n",
    "    print \"TRAIN: num of label \" + str(val) + \": \" + str(num_of_label(val, labels_train))\n",
    "\n",
    "### ERROR ANALYSIS ### \n",
    "print \"predictions: \"\n",
    "print predictions\n",
    "print \"actual: \"\n",
    "print labels_test\n",
    "\n",
    "print_accuracy(labels_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.   5.   6.   6.   6.   4.   6.   8.   6.   7.   3.   7.   5.   5.   3.\n",
      "   5.   8.  10.   4.   0.   1.   3.   7.   8.   9.   9.   7.   4.   6.   7.\n",
      "   6.   5.   5.   6.   5.   4.   3.   4.   6.   5.   4.   7.   3.   4.   3.\n",
      "   4.   5.   6.   4.   8.   8.   7.   6.   5.   7.   7.   4.]\n",
      "[ 4.  3.  5.  7.  1.  7.  5.  1.  5.  3.  7.  5.  7.  6.  1.  5.  7.  6.\n",
      "  5.  4.  7.  5.  6.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  1.\n",
      "  4.  6.  1.  2.  4.  1.  2.  6.  1.  2.  4.  6.  2.  6.  1.  2.  4.  6.\n",
      "  2.  1.  4.]\n",
      "num correct: 4\n",
      "num wrong: 53\n",
      "accuracy: 0.0701754385965\n"
     ]
    }
   ],
   "source": [
    "##LINEAR REGRESSION##\n",
    "from sklearn import linear_model\n",
    "#clf = linear_model.Ridge (alpha = .5)\n",
    "clf = linear_model.LinearRegression()\n",
    "clf.fit(features_train, labels_train)\n",
    "# print(\"coefficient: \")\n",
    "# clf.coef_\n",
    "# print(\"predict: \")\n",
    "test_results = clf.predict(features_test)\n",
    "updated_results = list()\n",
    "for result in test_results:\n",
    "    updated_results.append(int(round(result)))\n",
    "updated_results = np.array(updated_results).astype(np.float)\n",
    "print updated_results\n",
    "print labels_test\n",
    "\n",
    "print_accuracy(labels_test, updated_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num correct: 17\n",
      "num wrong: 110\n",
      "accuracy: 0.133858267717\n"
     ]
    }
   ],
   "source": [
    "##RANDOM##\n",
    "import random\n",
    "\n",
    "num_examples = len(predictions)\n",
    "random_labels = [random.randint(0,7) for p in range(0,num_examples)]\n",
    "# print random_labels\n",
    "# print labels_test\n",
    "print_accuracy(labels_test, random_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.35820896,  0.35820896,  0.28358209,  0.125     ,  0.11290323])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### CROSS VALIDATION ###\n",
    "from sklearn import metrics\n",
    "from sklearn import cross_validation\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "scores = cross_validation.cross_val_score(clf, features, labels, cv=5)\n",
    "\n",
    "scores                                              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
