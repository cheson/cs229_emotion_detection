{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from face_detection import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[307.13391,\n",
       " 201.99915,\n",
       " -0.0032405474,\n",
       " 438.5672,\n",
       " 194.86722,\n",
       " 3.1994605,\n",
       " 259.87903,\n",
       " 178.73419,\n",
       " 11.788714,\n",
       " 341.62595,\n",
       " 174.00339,\n",
       " -25.226755,\n",
       " 401.3927,\n",
       " 171.53769,\n",
       " -23.705614,\n",
       " 479.63004,\n",
       " 168.82491,\n",
       " 16.375118,\n",
       " 372.52872,\n",
       " 199.30902,\n",
       " -24.594208,\n",
       " 376.36417,\n",
       " 271.49146,\n",
       " -56.299461,\n",
       " 376.41443,\n",
       " 311.95346,\n",
       " -24.950884,\n",
       " 379.43185,\n",
       " 357.60095,\n",
       " -12.843111,\n",
       " 330.94168,\n",
       " 333.15857,\n",
       " 7.9911337,\n",
       " 425.30103,\n",
       " 329.61536,\n",
       " 10.754564,\n",
       " 377.99237,\n",
       " 332.6976,\n",
       " -14.308941,\n",
       " 410.32751,\n",
       " 277.12994,\n",
       " -7.0908031,\n",
       " 342.28757,\n",
       " 278.16431,\n",
       " -9.1516829,\n",
       " 375.8862,\n",
       " 291.78452,\n",
       " -26.689037,\n",
       " 310.23154,\n",
       " 195.10071,\n",
       " -8.9472837,\n",
       " 334.14941,\n",
       " 203.57199,\n",
       " 1.155954,\n",
       " 307.37128,\n",
       " 209.27304,\n",
       " -0.58583272,\n",
       " 284.04236,\n",
       " 204.14308,\n",
       " 11.06298,\n",
       " 308.60532,\n",
       " 203.3325,\n",
       " -3.3958294,\n",
       " 433.574,\n",
       " 189.92918,\n",
       " -5.8527708,\n",
       " 458.24335,\n",
       " 196.53714,\n",
       " 15.098604,\n",
       " 437.76068,\n",
       " 204.03271,\n",
       " 2.5838068,\n",
       " 411.06549,\n",
       " 200.5092,\n",
       " 3.0681994,\n",
       " 434.95612,\n",
       " 198.1026,\n",
       " -0.39119533,\n",
       " 303.67923,\n",
       " 160.28976,\n",
       " -17.755552,\n",
       " 437.48163,\n",
       " 154.69553,\n",
       " -14.405929,\n",
       " 230.20833,\n",
       " 257.35208,\n",
       " 153.89308,\n",
       " 510.29071,\n",
       " 245.66943,\n",
       " 160.78838,\n",
       " 371.52576,\n",
       " 171.56253,\n",
       " -29.364891,\n",
       " 380.52628,\n",
       " 410.45697,\n",
       " 7.4005833,\n",
       " 248.38145,\n",
       " 338.57758,\n",
       " 109.17309,\n",
       " 501.22156,\n",
       " 328.13782,\n",
       " 115.4831]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main('./images/CK+/cohn-kanade-plus-images/S005/001/S005_001_00000011.png', \"\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "17\n",
      "18\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "40\n",
      "42\n",
      "43\n",
      "47\n",
      "48\n",
      "49\n",
      "51\n",
      "54\n",
      "55\n",
      "56\n",
      "58\n",
      "60\n",
      "61\n",
      "63\n",
      "66\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "77\n",
      "78\n",
      "80\n",
      "82\n",
      "84\n",
      "85\n",
      "86\n",
      "89\n",
      "90\n",
      "91\n",
      "93\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "110\n",
      "113\n",
      "114\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "138\n",
      "139\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "151\n",
      "153\n",
      "154\n",
      "155\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "162\n",
      "163\n",
      "164\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "173\n",
      "174\n",
      "175\n",
      "180\n",
      "181\n",
      "182\n",
      "187\n",
      "188\n",
      "189\n",
      "191\n",
      "192\n",
      "194\n",
      "197\n",
      "198\n",
      "200\n",
      "201\n",
      "205\n",
      "206\n",
      "207\n",
      "212\n",
      "214\n",
      "217\n",
      "220\n",
      "221\n",
      "222\n",
      "224\n",
      "225\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "236\n",
      "237\n",
      "241\n",
      "243\n",
      "246\n",
      "248\n",
      "249\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "259\n",
      "260\n",
      "262\n",
      "263\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "275\n",
      "276\n",
      "278\n",
      "279\n",
      "280\n",
      "283\n",
      "284\n",
      "286\n",
      "287\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "297\n",
      "298\n",
      "299\n",
      "302\n",
      "304\n",
      "307\n",
      "308\n",
      "309\n",
      "312\n",
      "313\n",
      "314\n",
      "317\n",
      "318\n",
      "320\n",
      "325\n",
      "326\n",
      "332\n",
      "349\n",
      "351\n",
      "353\n",
      "355\n",
      "357\n",
      "361\n",
      "366\n",
      "367\n",
      "369\n",
      "372\n",
      "374\n",
      "375\n",
      "376\n",
      "383\n",
      "388\n",
      "389\n",
      "394\n",
      "395\n",
      "397\n",
      "402\n",
      "403\n",
      "408\n",
      "409\n",
      "412\n",
      "416\n",
      "417\n",
      "422\n",
      "423\n",
      "424\n",
      "426\n",
      "429\n",
      "437\n",
      "439\n",
      "444\n",
      "452\n",
      "456\n",
      "458\n",
      "461\n",
      "462\n",
      "463\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "476\n",
      "477\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "484\n",
      "485\n",
      "486\n",
      "492\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "499\n",
      "502\n",
      "504\n",
      "506\n",
      "507\n",
      "509\n",
      "510\n",
      "512\n",
      "515\n",
      "517\n",
      "518\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "528\n",
      "529\n",
      "531\n",
      "533\n",
      "534\n",
      "535\n",
      "539\n",
      "540\n",
      "541\n",
      "544\n",
      "545\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "['3', '7', '1', '5', '7', '6', '4', '1', '3', '5', '7', '6', '1', '5', '7', '1', '3', '7', '6', '1', '5', '1', '1', '7', '1', '4', '3', '5', '7', '1', '5', '7', '3', '5', '7', '1', '5', '7', '6', '1', '5', '7', '5', '3', '3', '1', '6', '7', '4', '3', '4', '7', '1', '5', '7', '3', '7', '5', '3', '7', '5', '4', '7', '3', '7', '3', '1', '5', '4', '3', '7', '5', '7', '3', '5', '7', '1', '3', '7', '4', '5', '7', '3', '7', '5', '3', '4', '7', '5', '3', '7', '5', '7', '5', '6', '4', '7', '5', '3', '7', '5', '6', '1', '7', '1', '5', '3', '5', '7', '4', '3', '7', '3', '5', '7', '5', '3', '7', '6', '1', '5', '3', '1', '5', '7', '3', '4', '7', '3', '5', '7', '3', '5', '1', '7', '3', '5', '7', '3', '7', '5', '3', '7', '3', '5', '7', '6', '3', '7', '6', '3', '7', '1', '3', '5', '7', '4', '5', '7', '3', '7', '5', '7', '3', '5', '1', '7', '3', '7', '5', '1', '7', '3', '1', '4', '5', '7', '1', '5', '6', '5', '7', '5', '7', '3', '5', '6', '7', '3', '5', '7', '3', '5', '3', '5', '7', '5', '3', '7', '1', '5', '7', '7', '4', '3', '3', '6', '3', '5', '7', '3', '6', '3', '5', '1', '3', '5', '7', '7', '1', '3', '1', '7', '6', '1', '7', '5', '7', '6', '5', '7', '3', '5', '7', '4', '1', '7', '4', '1', '7', '7', '4', '3', '5', '6', '5', '4', '7', '3', '7', '1', '7', '5', '1', '3', '5', '7', '1', '3', '5', '7', '1', '6', '3', '5', '7', '6', '5', '3', '6', '4', '3', '5', '7', '1', '7', '5', '1', '5', '3', '7', '5', '7', '6', '1', '5', '7', '6', '5', '4', '7', '5', '6', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '1', '4', '6', '1', '2', '4', '1', '2', '6', '1', '2', '4', '6', '2', '6', '1', '2', '4', '6', '2', '1', '4']\n",
      "[[307.13391, 201.99915, -0.0032405474, 438.5672, 194.86722, 3.1994605, 259.87903, 178.73419, 11.788714, 341.62595, 174.00339, -25.226755, 401.3927, 171.53769, -23.705614, 479.63004, 168.82491, 16.375118, 372.52872, 199.30902, -24.594208, 376.36417, 271.49146, -56.299461, 376.41443, 311.95346, -24.950884, 379.43185, 357.60095, -12.843111, 330.94168, 333.15857, 7.9911337, 425.30103, 329.61536, 10.754564, 377.99237, 332.6976, -14.308941, 410.32751, 277.12994, -7.0908031, 342.28757, 278.16431, -9.1516829, 375.8862, 291.78452, -26.689037, 310.23154, 195.10071, -8.9472837, 334.14941, 203.57199, 1.155954, 307.37128, 209.27304, -0.58583272, 284.04236, 204.14308, 11.06298, 308.60532, 203.3325, -3.3958294, 433.574, 189.92918, -5.8527708, 458.24335, 196.53714, 15.098604, 437.76068, 204.03271, 2.5838068, 411.06549, 200.5092, 3.0681994, 434.95612, 198.1026, -0.39119533, 303.67923, 160.28976, -17.755552, 437.48163, 154.69553, -14.405929, 230.20833, 257.35208, 153.89308, 510.29071, 245.66943, 160.78838, 371.52576, 171.56253, -29.364891, 380.52628, 410.45697, 7.4005833, 248.38145, 338.57758, 109.17309, 501.22156, 328.13782, 115.4831], [317.44684, 219.84222, -0.0010349125, 438.11414, 218.65933, -3.5251265, 274.52228, 192.03549, 11.983789, 348.25507, 192.66101, -25.871397, 407.4462, 190.807, -27.702435, 483.56204, 187.4339, 6.3616843, 376.88425, 211.53229, -28.315765, 379.38297, 288.10794, -62.38055, 380.55676, 335.62451, -31.913853, 380.36008, 376.97906, -21.657591, 331.76334, 352.20892, 3.495856, 429.49548, 350.82462, 0.61326987, 379.98349, 354.09827, -22.061695, 412.17209, 297.87689, -15.467205, 348.08936, 300.0011, -13.8211, 379.7373, 308.24521, -33.208042, 315.92642, 212.9984, -8.4694185, 341.39465, 223.35843, -0.072304167, 315.98972, 230.36493, -0.60887772, 291.86285, 221.90666, 12.29478, 314.2027, 221.61966, -2.7511659, 440.44592, 211.11838, -12.07887, 466.43634, 219.73264, 7.41956, 438.85361, 229.51802, -4.2892551, 413.23016, 222.29739, -2.3073146, 442.01181, 219.743, -6.637929, 309.98706, 176.96957, -15.55071, 445.14026, 174.83859, -19.46381, 242.62993, 279.14545, 157.64647, 525.30817, 274.92749, 149.57584, 377.30835, 189.71436, -31.529097, 381.81409, 432.484, -2.3284295, 255.90881, 360.22269, 108.83258, 511.62503, 356.49823, 101.42744], [316.81485, 228.28055, 0.00085463276, 434.6123, 222.6954, 0.30231711, 280.50116, 205.84967, 10.204757, 349.32352, 201.96439, -23.015432, 404.29538, 199.95007, -22.837585, 476.03488, 201.45213, 12.029448, 375.49313, 220.04424, -24.2055, 378.30298, 291.1778, -55.182304, 382.30768, 334.78076, -27.05566, 382.77124, 369.01764, -17.856461, 339.42081, 349.00922, 3.1919038, 428.27158, 345.40179, 4.4650016, 382.28708, 346.95471, -18.327934, 412.75995, 299.28876, -10.568548, 349.373, 303.95154, -10.992898, 380.22284, 310.90152, -28.350597, 320.65909, 221.64807, -7.96016, 342.5542, 227.57516, 0.50221747, 320.14636, 235.66864, -0.77933371, 298.26343, 230.03894, 10.349036, 319.28113, 229.35498, -2.925205, 434.19843, 217.67584, -7.5802336, 457.18781, 224.55511, 10.918723, 435.88019, 232.51102, -0.35338986, 410.87811, 225.54414, 0.67976665, 435.70474, 225.32939, -2.6672254, 314.89145, 189.3837, -14.874393, 438.06232, 185.08923, -14.384033, 250.11496, 283.21286, 141.64604, 508.1004, 274.20203, 142.47327, 376.81049, 199.70253, -27.313889, 384.53391, 420.61157, -0.25709668, 265.37082, 356.75031, 97.632378, 498.19049, 348.93448, 98.406891]]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from cd import cd\n",
    "\n",
    "def get_all_folders(folder_path):\n",
    "    with cd(folder_path):\n",
    "        all_folders = os.listdir('.')\n",
    "        directory_names = []\n",
    "        for directory in all_folders:\n",
    "            if directory[0] == '.':\n",
    "                continue\n",
    "            else:\n",
    "                directory_names.append(directory)\n",
    "        return directory_names\n",
    "    \n",
    "labels = list()\n",
    "features = list()\n",
    "\n",
    "def grab_data(Folder):\n",
    "    counter = 0\n",
    "    \n",
    "    ck_path = os.getcwd() + '/images/CK+/' + Folder + '/'\n",
    "    s_folders = get_all_folders(ck_path)\n",
    "    for folder in s_folders:\n",
    "        subdir_path = ck_path + folder + '/'\n",
    "        zero_folders = get_all_folders(subdir_path)\n",
    "        for zero in zero_folders:\n",
    "            img_level_path = subdir_path + zero + '/'\n",
    "            imgs = get_all_folders(img_level_path)\n",
    "            if Folder == 'Emotions': #LABELS\n",
    "                if len(imgs) > 0: #has an emotion label\n",
    "                    last_img_path = img_level_path + imgs[-1]\n",
    "                    f = open(last_img_path, 'r')\n",
    "                    emotion = f.read()\n",
    "                    labels.append(emotion[3]) #emotion[3] is the number denoting emotion\n",
    "                else: #has no emotion label\n",
    "                    labels.append(-1)\n",
    "            else: #FEATURES\n",
    "                last_img_path = img_level_path + imgs[-1]\n",
    "                if counter < len(labels): #TODO: CHECK THIS OFF BY ONE BULLSHIT\n",
    "                    if labels[counter] != -1:\n",
    "                        print counter\n",
    "                        features.append(main(last_img_path, \"\", 1))\n",
    "                counter += 1\n",
    "#                 if counter > 50: #because of bad internet\n",
    "#                     return\n",
    "\n",
    "grab_data('Emotions')\n",
    "grab_data('cohn-kanade-plus-images')\n",
    "temp_labels = list()\n",
    "for label in labels: #clean temp labels\n",
    "    if label != -1:\n",
    "        temp_labels.append(label)\n",
    "labels = temp_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.  7.  1.  5.  7.  6.  4.  1.  3.  5.  7.  6.  1.  5.  7.  1.  3.  7.\n",
      "  6.  1.  5.  1.  1.  7.  1.  4.  3.  5.  7.  1.  5.  7.  3.  5.  7.  1.\n",
      "  5.  7.  6.  1.  5.  7.  5.  3.  3.  1.  6.  7.  4.  3.  4.  7.  1.  5.\n",
      "  7.  3.  7.  5.  3.  7.  5.  4.  7.  3.  7.  3.  1.  5.  4.  3.  7.  5.\n",
      "  7.  3.  5.  7.  1.  3.  7.  4.  5.  7.  3.  7.  5.  3.  4.  7.  5.  3.\n",
      "  7.  5.  7.  5.  6.  4.  7.  5.  3.  7.  5.  6.  1.  7.  1.  5.  3.  5.\n",
      "  7.  4.  3.  7.  3.  5.  7.  5.  3.  7.  6.  1.  5.  3.  1.  5.  7.  3.\n",
      "  4.  7.  3.  5.  7.  3.  5.  1.  7.  3.  5.  7.  3.  7.  5.  3.  7.  3.\n",
      "  5.  7.  6.  3.  7.  6.  3.  7.  1.  3.  5.  7.  4.  5.  7.  3.  7.  5.\n",
      "  7.  3.  5.  1.  7.  3.  7.  5.  1.  7.  3.  1.  4.  5.  7.  1.  5.  6.\n",
      "  5.  7.  5.  7.  3.  5.  6.  7.  3.  5.  7.  3.  5.  3.  5.  7.  5.  3.\n",
      "  7.  1.  5.  7.  7.  4.  3.  3.  6.  3.  5.  7.  3.  6.  3.  5.  1.  3.\n",
      "  5.  7.  7.  1.  3.  1.  7.  6.  1.  7.  5.  7.  6.  5.  7.  3.  5.  7.\n",
      "  4.  1.  7.  4.  1.  7.  7.  4.  3.  5.  6.  5.  4.  7.  3.  7.  1.  7.\n",
      "  5.  1.  3.  5.  7.  1.  3.  5.  7.  1.  6.  3.  5.  7.  6.  5.  3.  6.\n",
      "  4.  3.  5.  7.  1.  7.  5.  1.  5.  3.  7.  5.  7.  6.  1.  5.  7.  6.\n",
      "  5.  4.  7.  5.  6.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  1.\n",
      "  4.  6.  1.  2.  4.  1.  2.  6.  1.  2.  4.  6.  2.  6.  1.  2.  4.  6.\n",
      "  2.  1.  4.]\n",
      "[[  3.07133910e+02   2.01999150e+02  -3.24054740e-03   4.38567200e+02\n",
      "    1.94867220e+02   3.19946050e+00   2.59879030e+02   1.78734190e+02\n",
      "    1.17887140e+01   3.41625950e+02   1.74003390e+02  -2.52267550e+01\n",
      "    4.01392700e+02   1.71537690e+02  -2.37056140e+01   4.79630040e+02\n",
      "    1.68824910e+02   1.63751180e+01   3.72528720e+02   1.99309020e+02\n",
      "   -2.45942080e+01   3.76364170e+02   2.71491460e+02  -5.62994610e+01\n",
      "    3.76414430e+02   3.11953460e+02  -2.49508840e+01   3.79431850e+02\n",
      "    3.57600950e+02  -1.28431110e+01   3.30941680e+02   3.33158570e+02\n",
      "    7.99113370e+00   4.25301030e+02   3.29615360e+02   1.07545640e+01\n",
      "    3.77992370e+02   3.32697600e+02  -1.43089410e+01   4.10327510e+02\n",
      "    2.77129940e+02  -7.09080310e+00   3.42287570e+02   2.78164310e+02\n",
      "   -9.15168290e+00   3.75886200e+02   2.91784520e+02  -2.66890370e+01\n",
      "    3.10231540e+02   1.95100710e+02  -8.94728370e+00   3.34149410e+02\n",
      "    2.03571990e+02   1.15595400e+00   3.07371280e+02   2.09273040e+02\n",
      "   -5.85832720e-01   2.84042360e+02   2.04143080e+02   1.10629800e+01\n",
      "    3.08605320e+02   2.03332500e+02  -3.39582940e+00   4.33574000e+02\n",
      "    1.89929180e+02  -5.85277080e+00   4.58243350e+02   1.96537140e+02\n",
      "    1.50986040e+01   4.37760680e+02   2.04032710e+02   2.58380680e+00\n",
      "    4.11065490e+02   2.00509200e+02   3.06819940e+00   4.34956120e+02\n",
      "    1.98102600e+02  -3.91195330e-01   3.03679230e+02   1.60289760e+02\n",
      "   -1.77555520e+01   4.37481630e+02   1.54695530e+02  -1.44059290e+01\n",
      "    2.30208330e+02   2.57352080e+02   1.53893080e+02   5.10290710e+02\n",
      "    2.45669430e+02   1.60788380e+02   3.71525760e+02   1.71562530e+02\n",
      "   -2.93648910e+01   3.80526280e+02   4.10456970e+02   7.40058330e+00\n",
      "    2.48381450e+02   3.38577580e+02   1.09173090e+02   5.01221560e+02\n",
      "    3.28137820e+02   1.15483100e+02]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "labels = np.array(labels).astype(np.float) #does it matter if the labels are strings or floats? what's the difference?\n",
    "#print labels\n",
    "\n",
    "features = np.array(features).astype(np.float)\n",
    "#print features[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327\n",
      "327\n"
     ]
    }
   ],
   "source": [
    "#sanity check\n",
    "print len(features)\n",
    "print len(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tools\n",
    "def train_test_split(split): \n",
    "    features_train = features[:split]\n",
    "    labels_train = labels[:split]\n",
    "    features_test = features[split:]\n",
    "    labels_test = labels[split:]\n",
    "    return (features_train, labels_train, features_test, labels_test)\n",
    "\n",
    "def num_of_label(val, labels):\n",
    "    count = 0\n",
    "    for label in labels:\n",
    "        if label == val:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def print_accuracy(labels_actual, labels_predicted):\n",
    "    correct = 0\n",
    "    wrong = 0\n",
    "    for index in range(len(labels_actual)):\n",
    "        if labels_actual[index] == labels_predicted[index]:\n",
    "            correct += 1\n",
    "        else:\n",
    "            wrong += 1\n",
    "    print 'num correct: ' + str(correct)\n",
    "    print 'num wrong: ' + str(wrong)\n",
    "    print 'accuracy: ' + str(float(correct)/(correct + wrong))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training SVM\n",
      "Finished Predictions for SVM\n",
      "training labels: \n",
      "[ 3.  7.  1.  5.  7.  6.  4.  1.  3.  5.  7.  6.  1.  5.  7.  1.  3.  7.\n",
      "  6.  1.  5.  1.  1.  7.  1.  4.  3.  5.  7.  1.  5.  7.  3.  5.  7.  1.\n",
      "  5.  7.  6.  1.  5.  7.  5.  3.  3.  1.  6.  7.  4.  3.  4.  7.  1.  5.\n",
      "  7.  3.  7.  5.  3.  7.  5.  4.  7.  3.  7.  3.  1.  5.  4.  3.  7.  5.\n",
      "  7.  3.  5.  7.  1.  3.  7.  4.  5.  7.  3.  7.  5.  3.  4.  7.  5.  3.\n",
      "  7.  5.  7.  5.  6.  4.  7.  5.  3.  7.  5.  6.  1.  7.  1.  5.  3.  5.\n",
      "  7.  4.  3.  7.  3.  5.  7.  5.  3.  7.  6.  1.  5.  3.  1.  5.  7.  3.\n",
      "  4.  7.  3.  5.  7.  3.  5.  1.  7.  3.  5.  7.  3.  7.  5.  3.  7.  3.\n",
      "  5.  7.  6.  3.  7.  6.  3.  7.  1.  3.  5.  7.  4.  5.  7.  3.  7.  5.\n",
      "  7.  3.  5.  1.  7.  3.  7.  5.  1.  7.  3.  1.  4.  5.  7.  1.  5.  6.\n",
      "  5.  7.  5.  7.  3.  5.  6.  7.  3.  5.  7.  3.  5.  3.  5.  7.  5.  3.\n",
      "  7.  1.  5.  7.  7.  4.  3.  3.  6.  3.  5.  7.  3.  6.  3.  5.  1.  3.\n",
      "  5.  7.  7.  1.  3.  1.  7.  6.  1.  7.  5.  7.  6.  5.  7.  3.  5.  7.\n",
      "  4.  1.  7.  4.  1.  7.  7.  4.  3.  5.  6.  5.  4.  7.  3.  7.]\n",
      "TRAIN: num of label 0: 0\n",
      "TRAIN: num of label 1: 32\n",
      "TRAIN: num of label 2: 0\n",
      "TRAIN: num of label 3: 53\n",
      "TRAIN: num of label 4: 18\n",
      "TRAIN: num of label 5: 57\n",
      "TRAIN: num of label 6: 17\n",
      "TRAIN: num of label 7: 73\n",
      "predictions: \n",
      "[ 4.  4.  4.  4.  4.  4.  4.  4.  7.  4.  4.  7.  7.  4.  4.  4.  4.  4.\n",
      "  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  7.  4.  4.  4.  4.  4.  4.\n",
      "  7.  4.  7.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.\n",
      "  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.\n",
      "  4.  4.  4.  4.  4.]\n",
      "actual: \n",
      "[ 1.  7.  5.  1.  3.  5.  7.  1.  3.  5.  7.  1.  6.  3.  5.  7.  6.  5.\n",
      "  3.  6.  4.  3.  5.  7.  1.  7.  5.  1.  5.  3.  7.  5.  7.  6.  1.  5.\n",
      "  7.  6.  5.  4.  7.  5.  6.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  1.  4.  6.  1.  2.  4.  1.  2.  6.  1.  2.  4.  6.  2.  6.  1.  2.\n",
      "  4.  6.  2.  1.  4.]\n",
      "num correct: 8\n",
      "num wrong: 69\n",
      "accuracy: 0.103896103896\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "#X is a matrix of input examples [[x1.....xn],...[x1,..., xn]]\n",
    "#Y is a vector of labels corresponding to emotion [1, 2, 8, ... yn]\n",
    "\n",
    "\n",
    "def train(X, y):\n",
    "#    clf = svm.SVC(decision_function_shape='ovo')\n",
    "    clf = svm.LinearSVC()\n",
    "    clf.fit(X,y)\n",
    "    print 'Finished Training SVM'\n",
    "    return clf\n",
    "\n",
    "def test(clf, X):\n",
    "    #Takes all examples to predict and returns an array of lables\n",
    "    predictions = clf.predict(X)\n",
    "    print 'Finished Predictions for SVM'\n",
    "    return predictions\n",
    "\n",
    "############ Sample usage ####################\n",
    "\n",
    "#X = [[0,1], [3,4], [6,2], [1,2]]\n",
    "#y = [1,2,3,4]\n",
    "    \n",
    "splits = train_test_split(250)\n",
    "features_train = splits[0]\n",
    "labels_train = splits[1]\n",
    "features_test = splits[2]\n",
    "labels_test = splits[3]\n",
    "\n",
    "clf = train(features_train, labels_train)\n",
    "predictions = test(clf, features_test)\n",
    "\n",
    "print \"training labels: \"\n",
    "print labels_train\n",
    "\n",
    "for val in range (0, 8):\n",
    "    print \"TRAIN: num of label \" + str(val) + \": \" + str(num_of_label(val, labels_train))\n",
    "\n",
    "print \"predictions: \"\n",
    "print predictions\n",
    "print \"actual: \"\n",
    "print labels_test\n",
    "\n",
    "# accuracy = \"105% and rising!\"\n",
    "# print \"accuracy:\"\n",
    "# print accuracy\n",
    "\n",
    "print_accuracy(labels_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4.   4.   5.   5.   3.   3.   1.   6.   6.   5.   7.   6.   6.   2.   5.\n",
      "   6.   5.   3.   3.   4.   4.   5.   3.   4.   5.   2.   4.   5.   4.   5.\n",
      "   3.   3.   6.   5.   2.   3.  11.   6.   8.   3.   1.   2.   7.   8.   9.\n",
      "   7.   6.   4.   4.   4.   5.   4.   3.   3.   3.   4.   3.   4.   5.   3.\n",
      "   5.   5.   5.   5.   7.   2.   3.   7.   4.   5.   6.   4.   5.   5.   6.\n",
      "   5.   2.]\n",
      "[ 1.  7.  5.  1.  3.  5.  7.  1.  3.  5.  7.  1.  6.  3.  5.  7.  6.  5.\n",
      "  3.  6.  4.  3.  5.  7.  1.  7.  5.  1.  5.  3.  7.  5.  7.  6.  1.  5.\n",
      "  7.  6.  5.  4.  7.  5.  6.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  1.  4.  6.  1.  2.  4.  1.  2.  6.  1.  2.  4.  6.  2.  6.  1.  2.\n",
      "  4.  6.  2.  1.  4.]\n",
      "num correct: 10\n",
      "num wrong: 67\n",
      "accuracy: 0.12987012987\n"
     ]
    }
   ],
   "source": [
    "##LINEAR REGRESSION##\n",
    "from sklearn import linear_model\n",
    "#clf = linear_model.Ridge (alpha = .5)\n",
    "clf = linear_model.LinearRegression()\n",
    "clf.fit(features_train, labels_train)\n",
    "# print(\"coefficient: \")\n",
    "# clf.coef_\n",
    "# print(\"predict: \")\n",
    "test_results = clf.predict(features_test)\n",
    "updated_results = list()\n",
    "for result in test_results:\n",
    "    updated_results.append(int(round(result)))\n",
    "updated_results = np.array(updated_results).astype(np.float)\n",
    "print updated_results\n",
    "print labels_test\n",
    "\n",
    "print_accuracy(labels_test, updated_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num correct: 12\n",
      "num wrong: 65\n",
      "accuracy: 0.155844155844\n"
     ]
    }
   ],
   "source": [
    "##RANDOM##\n",
    "import random\n",
    "\n",
    "num_examples = len(predictions)\n",
    "random_labels = [random.randint(0,7) for p in range(0,num_examples)]\n",
    "# print random_labels\n",
    "# print labels_test\n",
    "print_accuracy(labels_test, random_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "429\n",
    "437\n",
    "439\n",
    "444\n",
    "452\n",
    "456\n",
    "---------------------------------------------------------------------------\n",
    "KeyError                                  Traceback (most recent call last)\n",
    "<ipython-input-14-258d5e0ae85f> in <module>()\n",
    "     46 \n",
    "     47 grab_data('Emotions')\n",
    "---> 48 grab_data('cohn-kanade-plus-images')\n",
    "     49 temp_labels = list()\n",
    "     50 for label in labels: #clean temp labels\n",
    "\n",
    "<ipython-input-14-258d5e0ae85f> in grab_data(Folder)\n",
    "     42                 if labels[counter] != -1:\n",
    "     43                     print counter\n",
    "---> 44                     features.append(main(last_img_path, \"\", 1))\n",
    "     45                 counter += 1\n",
    "     46 \n",
    "\n",
    "/Users/Cheson/Documents/CS229Final/cs229_emotion_detection/face_detection.py in main(input_filename, output_filename, max_results)\n",
    "    110 def main(input_filename, output_filename, max_results):\n",
    "    111     with open(input_filename, 'rb') as image:\n",
    "--> 112         faces = detect_face(image, max_results)\n",
    "    113         #print('Found %s face%s' % (len(faces), '' if len(faces) == 1 else 's'))\n",
    "    114 \n",
    "\n",
    "/Users/Cheson/Documents/CS229Final/cs229_emotion_detection/face_detection.py in detect_face(face_file, max_results)\n",
    "     65         })\n",
    "     66     response = request.execute()\n",
    "---> 67     return response['responses'][0]['faceAnnotations']\n",
    "     68 # [END detect_face]\n",
    "     69 \n",
    "\n",
    "KeyError: 'faceAnnotations'\n",
    "\n",
    "In [ ]:\n",
    "\n",
    "from sklearn import svm\n",
    "â€‹\n",
    "#X is a matrix of input examples [[x1.....xn],...[x1,..., xn]]\n",
    "#Y is a vector o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
